{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZ9WIWTgve+2q9ZGJlP7U6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TarggORjjjV2","colab_type":"code","outputId":"75e931f1-9233-49dc-8139-5cb8a9851323","executionInfo":{"status":"ok","timestamp":1583570317378,"user_tz":-330,"elapsed":23076,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dGbRudtNjlqn","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/newYolo')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6F_mGalbos7T","colab_type":"code","colab":{}},"source":["#pip install -r requirements.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDe278IZlmct","colab_type":"code","outputId":"62613394-672b-4f6c-e859-54ba6a0eee96","executionInfo":{"status":"ok","timestamp":1583570328036,"user_tz":-330,"elapsed":3614,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import argparse\n","import numpy as np\n","from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n","from keras.layers.merge import add, concatenate\n","from keras.models import Model, load_model\n","from keras.preprocessing.image import load_img, save_img, img_to_array\n","from keras.backend import expand_dims\n","import struct\n","import cv2\n","from matplotlib import pyplot\n","from matplotlib.patches import Rectangle\n","import tensorflow as tf"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"LKbIncuSjnKl","colab_type":"code","colab":{}},"source":["#Making prediction"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1BlUyztkeWJ","colab_type":"code","outputId":"91103028-b6a2-4b5c-9b94-140f0a890f82","executionInfo":{"status":"ok","timestamp":1583570348237,"user_tz":-330,"elapsed":19806,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["# load yolov3 model\n","model = load_model('model2.h5')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","  warnings.warn('No training configuration found in save file: '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wvEBD2KOkggC","colab_type":"code","colab":{}},"source":["# load and prepare an image\n","def load_image_pixels(filename, shape):\n","    # load the image to get its shape\n","    image = load_img(filename, color_mode=\"grayscale\")\n","    width, height = image.size\n","    # load the image with the required size\n","    image = load_img(filename, target_size=shape, color_mode=\"grayscale\")\n","    # convert to numpy array\n","    image = img_to_array(image)\n","    # scale pixel values to [0, 1]\n","    image = image.astype('float32')\n","    image /= 255.0\n","    print(image)\n","    # add a dimension so that we have one sample\n","    image = expand_dims(image, 0)\n","    return image, width, height"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3i4jqQplU3u","colab_type":"code","outputId":"a81a51e4-7524-4028-e05f-9b7f91702035","executionInfo":{"status":"ok","timestamp":1583570349848,"user_tz":-330,"elapsed":16705,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":850}},"source":["# define the expected input shape for the model\n","input_w, input_h = 416, 416\n","# define our new photo\n","photo_filename = 'zebra.jpg'\n","# load and prepare image\n","image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[[[0.3137255 ]\n","  [0.45490196]\n","  [0.49803922]\n","  ...\n","  [0.22745098]\n","  [0.1882353 ]\n","  [0.17254902]]\n","\n"," [[0.36862746]\n","  [0.43137255]\n","  [0.43137255]\n","  ...\n","  [0.14117648]\n","  [0.13725491]\n","  [0.15294118]]\n","\n"," [[0.50980395]\n","  [0.47843137]\n","  [0.38431373]\n","  ...\n","  [0.08235294]\n","  [0.08235294]\n","  [0.13333334]]\n","\n"," ...\n","\n"," [[0.23921569]\n","  [0.1882353 ]\n","  [0.16470589]\n","  ...\n","  [0.53333336]\n","  [0.53333336]\n","  [0.49803922]]\n","\n"," [[0.26666668]\n","  [0.2       ]\n","  [0.18431373]\n","  ...\n","  [0.5764706 ]\n","  [0.57254905]\n","  [0.54509807]]\n","\n"," [[0.2509804 ]\n","  [0.2627451 ]\n","  [0.21568628]\n","  ...\n","  [0.5803922 ]\n","  [0.5803922 ]\n","  [0.5686275 ]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LW8ML3Ghm3tl","colab_type":"code","outputId":"eae406d7-f6de-468b-89bc-87509c65ed22","executionInfo":{"status":"ok","timestamp":1583570349850,"user_tz":-330,"elapsed":14233,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(image,image_w, image_h)\n","print(image)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Tensor(\"ExpandDims:0\", shape=(1, 416, 416, 1), dtype=float32) 640 386\n","Tensor(\"ExpandDims:0\", shape=(1, 416, 416, 1), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jIsqHPVaXdU2","colab_type":"code","outputId":"ea0947f2-f98c-4c21-e2d0-a1031dfbf318","executionInfo":{"status":"ok","timestamp":1583570350841,"user_tz":-330,"elapsed":14643,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Working\n","trainsample = np.load('SampleDataTrainTest/trainDataSample.npy')\n","trainsample.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60, 256, 256)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"YUNsYZFgOO12","colab_type":"code","colab":{}},"source":["#Testing\n","trainData = np.load('trainset_100_416.npy')\n","target = np.load('targetData_100_4.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmtM7Bz5hsvw","colab_type":"code","outputId":"420a04d5-64f0-4a65-f7ea-cd9bb7e58955","executionInfo":{"status":"ok","timestamp":1583570353023,"user_tz":-330,"elapsed":15147,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(trainData.shape)\n","trainData = np.expand_dims(trainData,-1)\n","print(trainData.shape)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["(100, 416, 416)\n","(100, 416, 416, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_ZeIc2JTjxD5","colab_type":"code","colab":{}},"source":["trainData = np.load('SampleDataTrainTest/trainDataSample.npy',allow_pickle=True)\n","trainDataBounding = np.load('SampleDataTrainTest/trainBoundingDataSample.npy',allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukJewpIVlR5T","colab_type":"code","colab":{}},"source":["from tensorflow.keras.applications.mobilenet import preprocess_input\n","\n","IMAGE_WIDTH = 224\n","IMAGE_HEIGHT = 224\n","\n","X_train = np.zeros((int(trainData.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n","for index in range(trainData.shape[0]):\n","    img = trainData[index]\n","    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n","    img = np.stack((img,)*3, axis=-1)\n","    X_train[index] = preprocess_input(np.array(img, dtype=np.float32))\n","\n","### Creating the masks array\n","masks = np.zeros((int(trainData.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\n","for i in range(0,len(trainDataBounding)):\n","  for bbDims in range(0,len(trainDataBounding[i])):\n","    try:\n","      x1 = (int(trainDataBounding[i][bbDims][1]))\n","      y1 = (int(trainDataBounding[i][bbDims][2]))\n","      x2 = ((int(trainDataBounding[i][bbDims][1]) + int(trainDataBounding[i][bbDims][3])))\n","      y2 = ((int(trainDataBounding[i][bbDims][2]) + int(trainDataBounding[i][bbDims][5])))\n","      masks[i][y1:(y1+y2),x1:(x1+x2)] = 1\n","    except:\n","      pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gt6odgEbnnG3","colab_type":"code","outputId":"1000040d-50f7-4ba1-e1e4-ef28edbdd15e","executionInfo":{"status":"ok","timestamp":1583435917898,"user_tz":-330,"elapsed":30166,"user":{"displayName":"suhas -","photoUrl":"","userId":"06056528167229844402"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# make prediction\n","model.compile(optimizer='adam', loss='binary_crossentropy')\n","model.fit(X_train, masks, steps_per_epoch=1)\n","#yhat = model.predict(image, steps = 1)\n","# summarize the shape of the list of arrays\n","#print([a.shape for a in yhat])\n","#print(yhat)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-zBCUE6pn36K","colab_type":"code","colab":{}},"source":["class BoundBox:\n","\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n","\t\tself.xmin = xmin\n","\t\tself.ymin = ymin\n","\t\tself.xmax = xmax\n","\t\tself.ymax = ymax\n","\t\tself.objness = objness\n","\t\tself.classes = classes\n","\t\tself.label = -1\n","\t\tself.score = -1\n"," \n","\tdef get_label(self):\n","\t\tif self.label == -1:\n","\t\t\tself.label = np.argmax(self.classes)\n"," \n","\t\treturn self.label\n"," \n","\tdef get_score(self):\n","\t\tif self.score == -1:\n","\t\t\tself.score = self.classes[self.get_label()]\n"," \n","\t\treturn self.score\n"," \n","def _sigmoid(x):\n","\treturn 1. / (1. + np.exp(-x))\n"," \n","def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n","\tgrid_h, grid_w = netout.shape[:2]\n","\tnb_box = 3\n","\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1))\n","\tnb_class = netout.shape[-1] - 5\n","\tboxes = []\n","\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n","\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n","\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n","\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n"," \n","\tfor i in range(grid_h*grid_w):\n","\t\trow = i / grid_w\n","\t\tcol = i % grid_w\n","\t\tfor b in range(nb_box):\n","\t\t\t# 4th element is objectness score\n","\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n","\t\t\tif(objectness.all() <= obj_thresh): continue\n","\t\t\t# first 4 elements are x, y, w, and h\n","\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n","\t\t\tx = (col + x) / grid_w # center position, unit: image width\n","\t\t\ty = (row + y) / grid_h # center position, unit: image height\n","\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n","\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n","\t\t\t# last elements are class probabilities\n","\t\t\tclasses = netout[int(row)][col][b][5:]\n","\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n","\t\t\tboxes.append(box)\n","\treturn boxes\n"," \n","def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n","\tnew_w, new_h = net_w, net_h\n","\tfor i in range(len(boxes)):\n","\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n","\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n","\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n","\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n","\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n","\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"," \n","def _interval_overlap(interval_a, interval_b):\n","\tx1, x2 = interval_a\n","\tx3, x4 = interval_b\n","\tif x3 < x1:\n","\t\tif x4 < x1:\n","\t\t\treturn 0\n","\t\telse:\n","\t\t\treturn min(x2,x4) - x1\n","\telse:\n","\t\tif x2 < x3:\n","\t\t\t return 0\n","\t\telse:\n","\t\t\treturn min(x2,x4) - x3\n"," \n","def bbox_iou(box1, box2):\n","\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n","\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n","\tintersect = intersect_w * intersect_h\n","\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n","\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n","\tunion = w1*h1 + w2*h2 - intersect\n","\treturn float(intersect) / union\n"," \n","def do_nms(boxes, nms_thresh):\n","\tif len(boxes) > 0:\n","\t\tnb_class = len(boxes[0].classes)\n","\telse:\n","\t\treturn\n","\tfor c in range(nb_class):\n","\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n","\t\tfor i in range(len(sorted_indices)):\n","\t\t\tindex_i = sorted_indices[i]\n","\t\t\tif boxes[index_i].classes[c] == 0: continue\n","\t\t\tfor j in range(i+1, len(sorted_indices)):\n","\t\t\t\tindex_j = sorted_indices[j]\n","\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n","\t\t\t\t\tboxes[index_j].classes[c] = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcVvD-xPr4ZD","colab_type":"code","colab":{}},"source":["# get all of the results above a threshold\n","def get_boxes(boxes, labels, thresh):\n","\tv_boxes, v_labels, v_scores = list(), list(), list()\n","\t# enumerate all boxes\n","\tfor box in boxes:\n","\t\t# enumerate all possible labels\n","\t\tfor i in range(len(labels)):\n","\t\t\t# check if the threshold for this label is high enough\n","\t\t\tif box.classes[i] > thresh:\n","\t\t\t\tv_boxes.append(box)\n","\t\t\t\tv_labels.append(labels[i])\n","\t\t\t\tv_scores.append(box.classes[i]*100)\n","\t\t\t\t# don't break, many labels may trigger for one box\n","\treturn v_boxes, v_labels, v_scores\n"," \n","# draw all results\n","def draw_boxes(filename, v_boxes, v_labels, v_scores):\n","\t# load the image\n","\tdata = pyplot.imread(filename)\n","\t# plot the image\n","\tpyplot.imshow(data)\n","\t# get the context for drawing boxes\n","\tax = pyplot.gca()\n","\t# plot each box\n","\tfor i in range(len(v_boxes)):\n","\t\tbox = v_boxes[i]\n","\t\t# get coordinates\n","\t\ty1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n","\t\t# calculate width and height of the box\n","\t\twidth, height = x2 - x1, y2 - y1\n","\t\t# create the shape\n","\t\trect = Rectangle((x1, y1), width, height, fill=False, color='white')\n","\t\t# draw the box\n","\t\tax.add_patch(rect)\n","\t\t# draw text and score in top left corner\n","\t\tlabel = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n","\t\tpyplot.text(x1, y1, label, color='white')\n","\t# show the plot\n","\tpyplot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SS8VRoClr9H-","colab_type":"code","colab":{}},"source":["# define the anchors\n","anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n","# define the probability threshold for detected objects\n","class_threshold = 0.6\n","boxes = list()\n","for i in range(len(yhat)):\n","\t# decode the output of the network\n","\tboxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n","# correct the sizes of the bounding boxes for the shape of the image\n","correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n","# suppress non-maximal boxes\n","do_nms(boxes, 0.5)\n","# define the labels\n","labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n","\t\"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n","\t\"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n","\t\"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n","\t\"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n","\t\"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n","\t\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n","\t\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n","\t\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n","\t\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n","# get the details of the detected objects\n","v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n","# summarize what we found\n","for i in range(len(v_boxes)):\n","\tprint(v_labels[i], v_scores[i])\n","# draw what we found\n","draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aMoXreYsGZH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}